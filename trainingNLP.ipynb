{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = torch.Tensor(\n",
    "    [\n",
    "        0, #can\n",
    "        7, #you\n",
    "        1, #help\n",
    "        2, #me \n",
    "        5, #to\n",
    "        6, #translate\n",
    "        4, #this\n",
    "        3, #sentence\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 1, 2, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after the sentence being encoded in \n",
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(10, 16)\n",
    "embedded_sentence = embed(sentence.long()).detach()\n",
    "embedded_sentence.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega  = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embedded_sentence):\n",
    "    for j, x_j in enumerate(embedded_sentence):\n",
    "        omega[i,j] = torch.dot(x_i,x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "omega_mat = embedded_sentence.matmul(embedded_sentence.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify if the matrix multiplication produce the expected result btw omega_mat and omega.\n",
    "#In a project no need to go for \"for loop\" due to it inefficient compare to matrix multiplication.\n",
    "torch.allclose(omega_mat, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention weight normalization using softmax function \n",
    "import torch.nn.functional as F\n",
    "attention_weights  = F.softmax(omega_mat, dim = 1)\n",
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3420e-01, -1.8324e-01, -3.0218e-01, -5.7772e-01,  3.5662e-01,\n",
       "          6.6452e-01, -2.0998e-01, -3.7798e-01,  7.6537e-01, -1.1946e+00,\n",
       "          6.9960e-01, -1.4067e+00,  1.7021e-01,  1.8838e+00,  4.8729e-01,\n",
       "          2.4730e-01],\n",
       "        [-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
       "         -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
       "         -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
       "         -2.1601e+00],\n",
       "        [-7.7021e-02, -1.0205e+00, -1.6895e-01,  9.1776e-01,  1.5810e+00,\n",
       "          1.3010e+00,  1.2753e+00, -2.0095e-01,  4.9647e-01, -1.5723e+00,\n",
       "          9.6657e-01, -1.1481e+00, -1.1589e+00,  3.2547e-01, -6.3151e-01,\n",
       "         -2.8400e+00],\n",
       "        [-1.3679e+00,  1.0614e-01, -2.1317e+00,  1.0480e+00, -3.7127e-01,\n",
       "         -9.1234e-01, -4.3802e-01, -1.0329e+00,  9.3425e-01,  1.5453e+00,\n",
       "          5.7218e-01, -1.8049e-01, -6.0456e-03, -8.8691e-02,  2.0559e-01,\n",
       "         -5.2292e-01],\n",
       "        [ 2.5444e-01, -5.5082e-01,  1.0012e+00,  8.2746e-01, -3.8978e-01,\n",
       "          4.9129e-01, -2.1302e-01, -1.7432e+00, -1.5972e+00, -1.0776e+00,\n",
       "          9.0331e-01, -7.2292e-01, -5.9652e-01, -7.0857e-01,  6.1977e-01,\n",
       "         -1.3766e+00],\n",
       "        [-2.2150e+00, -1.3193e+00, -2.0915e+00,  9.6285e-01, -3.1862e-02,\n",
       "         -4.7896e-01,  7.6681e-01,  2.7467e-02,  1.9929e+00,  1.3708e+00,\n",
       "         -5.0087e-01, -2.7928e-01, -2.0628e+00,  6.3744e-03, -9.8955e-01,\n",
       "          7.0161e-01],\n",
       "        [ 5.1463e-01,  9.9376e-01, -2.5873e-01, -1.0825e+00, -4.4383e-02,\n",
       "          1.6236e+00, -2.3229e+00,  1.0878e+00,  6.7156e-01,  6.9329e-01,\n",
       "         -9.4872e-01, -7.6506e-02, -1.5264e-01,  1.1674e-01,  4.4026e-01,\n",
       "         -1.4465e+00],\n",
       "        [ 8.7683e-01,  1.6221e+00, -1.4779e+00,  1.1331e+00, -1.2203e+00,\n",
       "          1.3139e+00,  1.0533e+00,  1.3881e-01,  2.2473e+00, -8.0363e-01,\n",
       "         -2.8084e-01,  7.6968e-01, -6.5956e-01, -7.9793e-01,  1.8383e-01,\n",
       "          2.2935e-01]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = torch.matmul(attention_weights, embedded_sentence)\n",
    "context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
